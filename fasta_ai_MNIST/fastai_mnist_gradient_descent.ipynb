{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0fa4acb-0e0b-4fd3-a233-69efadca6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time\n",
    "from urllib.error import URLError, HTTPError\n",
    "import fastai\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc6ae20-fde2-4d92-bb25-32ad1e066828",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup\n",
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c16327d1-db3d-47c4-b0bf-5923e410f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grabbing the data we want to start with\n",
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7467f5b9-8769-4399-a583-f88330209b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load all of the images in as tensors\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens] \n",
    "three_tensors = [tensor(Image.open(o)) for o in threes] \n",
    "len(three_tensors),len(seven_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79fdf227-d786-4149-9119-b76315d9931a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Stack the tensors, and normalize to values between 0 and 1\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_threes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b73c488-27cb-4596-acb4-f00add125514",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What does the 'average' digit look like?\n",
    "mean3 = stacked_threes.mean(0)\n",
    "mean7 = stacked_sevens.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b039d285-e376-4c2b-9f18-be3393260407",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grabbing arbitrary digits\n",
    "a_3 = stacked_threes[21]\n",
    "a_7 = stacked_sevens[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b440e9e1-dd4f-4771-a9fa-f61daef6c7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grab and normaize the validation data\n",
    "valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()]) \n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "\n",
    "valid_3_tens.shape,valid_7_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19030e7d-8c2f-4719-8ffa-a0d69b53eb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (fastai)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
