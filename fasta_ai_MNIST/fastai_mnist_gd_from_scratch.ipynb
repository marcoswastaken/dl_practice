{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0fa4acb-0e0b-4fd3-a233-69efadca6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time\n",
    "from urllib.error import URLError, HTTPError\n",
    "import fastai\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f1f9ad-a270-4313-90d9-9569a693856a",
   "metadata": {},
   "source": [
    "# Classifying Digits\n",
    "\n",
    "The goal here is to build a model that classifies digits, and to improve the model parameters using gradient descent.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, load the data into tensors for training with a PyTorch model (assisted by fastai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc6ae20-fde2-4d92-bb25-32ad1e066828",
   "metadata": {},
   "outputs": [],
   "source": [
    "##. Get the raw data, MNIST 3's and 7's\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "\n",
    "##. Get the path names for all of the images files\n",
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "\n",
    "##. Load all of the images in as tensors\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens] \n",
    "three_tensors = [tensor(Image.open(o)) for o in threes] \n",
    "\n",
    "##. Stack the tensors, and normalize entries to values between 0 and 1\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "\n",
    "##. Compute the mean of each digit for validation against baseline\n",
    "mean3 = stacked_threes.mean(0)\n",
    "mean7 = stacked_sevens.mean(0)\n",
    "\n",
    "##. Select a couple arbitrary digits for illustration\n",
    "a_3 = stacked_threes[21]\n",
    "a_7 = stacked_sevens[33]\n",
    "\n",
    "##. Prepare the validation data (normalize it like the training data)\n",
    "valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()]) \n",
    "valid_7_tens = valid_7_tens.float()/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc421cbb-8d76-47bb-80aa-92f47431dfc4",
   "metadata": {},
   "source": [
    "## Preparing the training data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b7fa2bd-b3c6-4456-964c-50ad5c5c5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##. Concatenate the training data into a single tensor\n",
    "##. and reshape (using .view) it into a rank-2 tensor\n",
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1,28*28)\n",
    "\n",
    "##. Assign the target values 1: three, 0:seven\n",
    "##. Then, reshape it as a column vector (using unsqueeze)\n",
    "train_y = tensor([1]*len(threes)+[0]*len(sevens)).unsqueeze(1)\n",
    "\n",
    "##. Prepare the data to be used with `Dataset` in PyTorch\n",
    "dset = list(zip(train_x, train_y))\n",
    "##. Initialize x and y values\n",
    "x,y = dset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274fae35-a2e8-4291-9145-d613712660f4",
   "metadata": {},
   "source": [
    "## Praparing the validation data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1613d966-2c07-49f9-a0b5-bbba81c2cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##. Concatenate the validation data into a single tensor\n",
    "##. and reshape (using .view) it into a rank-2 tensor\n",
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1,28*28)\n",
    "\n",
    "##. Assign the target values 1: three, 0:seven\n",
    "##. Then, reshape it as a column vector (using unsqueeze)\n",
    "valid_y = tensor([1]*len(valid_3_tens)+[0]*len(valid_7_tens)).unsqueeze(1)\n",
    "\n",
    "##. Prepare the data to be used with `Dataset` in PyTorch\n",
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902b24bc-17c2-4ca2-9ea5-afb8c9c89f4c",
   "metadata": {},
   "source": [
    "## Initializing the model\n",
    "The model needs an initial set of weights and a bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c25f908-a007-4f2a-b702-4688fd01f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0):\n",
    "    ##. Initialize parameters with random values, and make sure the tensor\n",
    "    ##. is prepped for computing the gradient at the point\n",
    "    return (torch.randn(size)*std).requires_grad_()\n",
    "\n",
    "##. Initialize the model weights and bias\n",
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)\n",
    "\n",
    "##. Make a function for computing the predictions as y=Wx+b\n",
    "def linear1(xb): \n",
    "    return xb@weights + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3448f7-2606-46fd-858b-86c4c90b1f99",
   "metadata": {},
   "source": [
    "### Defining a loss function and an activation function\n",
    "\n",
    "#### First attempt loss function\n",
    "As a first attempt, we can define a loss function that just measures the distance from the predictions and the targets by looking at the predictions for each training example and scoring it as 1 (incorrect) or 0 (correct), then taking the average of those scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ef72750-1646-42ec-94bf-94056ac89488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    easy_loss = torch.where(targets==1, 1-predictions, predictions).mean()\n",
    "    return easy_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ebdc7d-77b7-40a7-a89e-22ab11aeb947",
   "metadata": {},
   "source": [
    "This is great, but its super simple and doesn't ensure that out predictions will lie between 0 and 1, which we definitely want since we are doing a binary classification.\n",
    "\n",
    "#### A second attempt... adding an activation function\n",
    "\n",
    "We can add the the classic sigmoid activation function to our loss function to ensure values are in the range 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79ed68b6-a08b-4712-be87-8c5423323fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): \n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    easy_loss_with_sigmoid = torch.where(targets==1, 1-predictions, predictions).mean()\n",
    "    return easy_loss_with_sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fcf560-cbec-4647-93ec-95334708d8f5",
   "metadata": {},
   "source": [
    "Building, training, updating..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e0def5-a68b-4b7f-a7c6-1b89dade3ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.4007],\n",
       "        [-5.7881],\n",
       "        [ 9.2380],\n",
       "        [12.7564],\n",
       "        [ 2.6253],\n",
       "        [12.2671],\n",
       "        [-7.5896],\n",
       "        [12.7323],\n",
       "        [ 7.1000],\n",
       "        [14.6207]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##. Create a DataLoader from the training Dataset\n",
    "dl = DataLoader(dset, batch_size=256)\n",
    "##. Load a batch of training data\n",
    "xb, yb = first(dl)\n",
    "\n",
    "##. Create a DataLoader from the validation Dataset\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)\n",
    "\n",
    "##. Grab a batch for testing\n",
    "batch = train_x[:10]\n",
    "\n",
    "##. Make predictions on the test batch\n",
    "preds = linear1(batch)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27c419a4-1f82-4f14-bf08-96a54c98aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##. Define a function to compute the gradient\n",
    "def calc_grad(xb, yb, model):\n",
    "    ##. Compute the prediction using the current model\n",
    "    preds = model(xb)\n",
    "    ##. Compute the loss of the current predictions\n",
    "    loss = mnist_loss(preds, yb) \n",
    "    ##. Backpropagate the gradient of the loss at the current inputs\n",
    "    loss.backward()\n",
    "\n",
    "##. Define a function that perfoms an epoch of training to update weights and bias\n",
    "def train_epoch(model, lr, params): \n",
    "    ##.  For every batch of data in the DataLoader\n",
    "    for xb,yb in dl:\n",
    "        ##. Compute the gradient of loss the current model at that batch of inputs\n",
    "        calc_grad(xb, yb, model) \n",
    "        for p in params:\n",
    "            ##. Update the parameteres in the direction of the gradient\n",
    "            ##. scalled by the learning rate\n",
    "            p.data -= p.grad*lr\n",
    "            ##. Reset the gradient to zero for the next batch\n",
    "            p.grad.zero_()\n",
    "\n",
    "##. Define a function that calculates the accuracy on a batch\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb \n",
    "    return correct.float().mean()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl] \n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc5e0080-b16a-47e6-becd-19bed00ee06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(linear1(batch), train_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0ff0991-f9fc-4d89-99ff-5f13f17d968e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3755"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed51b632-491d-4150-a695-f82b18445356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 30 epochs: 0.9789\n",
      "Accuracy after 60 epochs: 0.9828\n",
      "Accuracy after 90 epochs: 0.9838\n",
      "Accuracy after 120 epochs: 0.9838\n",
      "Accuracy after 150 epochs: 0.9848\n",
      "Accuracy after 180 epochs: 0.9857\n",
      "Accuracy after 210 epochs: 0.9862\n",
      "Accuracy after 240 epochs: 0.9858\n",
      "Accuracy after 270 epochs: 0.9858\n",
      "Accuracy after 300 epochs: 0.9858\n"
     ]
    }
   ],
   "source": [
    "##. Initialize the model parameters to random weights and bias\n",
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)\n",
    "params = weights, bias\n",
    "\n",
    "##. Define the learning rate\n",
    "lr = 1\n",
    "\n",
    "##. Iterate over several training eopchs\n",
    "for i in range(1, 301):\n",
    "    train_epoch(linear1, lr, params) \n",
    "    if i%30 ==0:\n",
    "        print(f'Accuracy after {i} epochs: {validate_epoch(linear1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be847d6f-a2b7-41cb-915f-e9d5f185da8d",
   "metadata": {},
   "source": [
    "Neat... but i don't need to do this from scratch every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb6c52e-c0a5-43ae-aad0-59a9e26363c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (fastai)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
