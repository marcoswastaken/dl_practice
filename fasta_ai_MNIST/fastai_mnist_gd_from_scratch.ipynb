{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0fa4acb-0e0b-4fd3-a233-69efadca6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time\n",
    "from urllib.error import URLError, HTTPError\n",
    "import fastai\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f1f9ad-a270-4313-90d9-9569a693856a",
   "metadata": {},
   "source": [
    "# Classifying Digits\n",
    "\n",
    "The goal here is to build a model that classifies digits, and to improve the model parameters using gradient descent.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, load the data into tensors for training with a PyTorch model (assisted by fastai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc6ae20-fde2-4d92-bb25-32ad1e066828",
   "metadata": {},
   "outputs": [],
   "source": [
    "##. Get the raw data, MNIST 3's and 7's\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "\n",
    "##. Get the path names for all of the images files\n",
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "\n",
    "##. Load all of the images in as tensors\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens] \n",
    "three_tensors = [tensor(Image.open(o)) for o in threes] \n",
    "\n",
    "##. Stack the tensors, and normalize entries to values between 0 and 1\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "\n",
    "##. Compute the mean of each digit for validation against baseline\n",
    "mean3 = stacked_threes.mean(0)\n",
    "mean7 = stacked_sevens.mean(0)\n",
    "\n",
    "##. Select a couple arbitrary digits for illustration\n",
    "a_3 = stacked_threes[21]\n",
    "a_7 = stacked_sevens[33]\n",
    "\n",
    "##. Prepare the validation data (normalize it like the training data)\n",
    "valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()]) \n",
    "valid_7_tens = valid_7_tens.float()/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc421cbb-8d76-47bb-80aa-92f47431dfc4",
   "metadata": {},
   "source": [
    "## Preparing the training data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b7fa2bd-b3c6-4456-964c-50ad5c5c5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##. Concatenate the training data into a single tensor\n",
    "##. and reshape (using .view) it into a rank-2 tensor\n",
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1,28*28)\n",
    "\n",
    "##. Assign the target values 1: three, 0:seven\n",
    "##. Then, reshape it as a column vector (using unsqueeze)\n",
    "train_y = tensor([1]*len(threes)+[0]*len(sevens)).unsqueeze(1)\n",
    "\n",
    "##. Prepare the data to be used with `Dataset` in PyTorch\n",
    "dset = list(zip(train_x, train_y))\n",
    "##. Initialize x and y values\n",
    "x,y = dset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274fae35-a2e8-4291-9145-d613712660f4",
   "metadata": {},
   "source": [
    "## Praparing the validation data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1613d966-2c07-49f9-a0b5-bbba81c2cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##. Concatenate the validation data into a single tensor\n",
    "##. and reshape (using .view) it into a rank-2 tensor\n",
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1,28*28)\n",
    "\n",
    "##. Assign the target values 1: three, 0:seven\n",
    "##. Then, reshape it as a column vector (using unsqueeze)\n",
    "valid_y = tensor([1]*len(valid_3_tens)+[0]*len(valid_7_tens)).unsqueeze(1)\n",
    "\n",
    "##. Prepare the data to be used with `Dataset` in PyTorch\n",
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902b24bc-17c2-4ca2-9ea5-afb8c9c89f4c",
   "metadata": {},
   "source": [
    "## Initializing the model\n",
    "The model needs an initial set of weights and a bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c25f908-a007-4f2a-b702-4688fd01f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0):\n",
    "    ##. Initialize parameters with random values, and make sure the tensor\n",
    "    ##. is prepped for computing the gradient at the point\n",
    "    return (torch.randn(size)*std).requires_grad_()\n",
    "\n",
    "##. Initialize the model weights and bias\n",
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3448f7-2606-46fd-858b-86c4c90b1f99",
   "metadata": {},
   "source": [
    "### Defining a loss function and an activation function\n",
    "\n",
    "#### First attempt loss function\n",
    "As a first attempt, we can define a loss function that just measures the distance from the predictions and the targets by looking at the predictions for each training example and scoring it as 1 (incorrect) or 0 (correct), then taking the average of those scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ef72750-1646-42ec-94bf-94056ac89488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    easy_loss = torch.where(targets==1, 1-predictions, predictions).mean()\n",
    "    return easy_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ebdc7d-77b7-40a7-a89e-22ab11aeb947",
   "metadata": {},
   "source": [
    "This is great, but its super simple and doesn't ensure that out predictions will lie between 0 and 1, which we definitely want since we are doing a binary classification.\n",
    "\n",
    "#### A second attempt... adding an activation function\n",
    "\n",
    "We can add the the classic sigmoid activation function to our loss function to ensure values are in the range 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79ed68b6-a08b-4712-be87-8c5423323fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): \n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    easy_loss_with_sigmoid = torch.where(targets==1, 1-predictions, predictions).mean()\n",
    "    return easy_loss_with_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a711515-eeb7-4fa0-ab0f-c4594ec70f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (fastai)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
